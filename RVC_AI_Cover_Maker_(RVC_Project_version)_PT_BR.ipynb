{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RVC AI Cover Maker (RVC Project) PT-BR\n",
        "Criado por [ShiromiyaG](https://github.com/ShiromiyaG)\n",
        "- Colab inspirado no [AICoverGen](https://github.com/SociallyIneptWeeb/AICoverGen) por [SociallyIneptWeeb](https://github.com/SociallyIneptWeeb)\n",
        "- Usa a versão do [RVC-Project](https://github.com/RVC-Project) do [Retrieval-based-Voice-Conversion](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion)"
      ],
      "metadata": {
        "id": "q2v07vI0d3tU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0mfD-nIXC_M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from IPython.display import clear_output\n",
        "import subprocess\n",
        "import fileinput\n",
        "import zipfile\n",
        "import shutil\n",
        "import sys\n",
        "import base64\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "Path('/content/drive/MyDrive/RVC AI Cover Maker Input').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/musicas/arquivos-originais').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/dependencias').mkdir(parents=True, exist_ok=True)\n",
        "os.chdir(\"/content\")\n",
        "# @title # Instalar\n",
        "# @markdown ##### Sim, leva um tempo\n",
        "# @markdown ##### Deixe os arquivos extras somente se for usar Enemble nos vocais\n",
        "voc_extra_files = True #@param {type:\"boolean\"}\n",
        "# @markdown ##### Para achar bugs, tem a opção de não limpar o output **(Pode causar crashes)**\n",
        "not_clean_outputs = False #@param {type:\"boolean\"}\n",
        "# @markdown ##### Install precompiled pip dependencies for faster installation **(May be dated)**\n",
        "precompiled = True #@param {type:\"boolean\"}\n",
        "if precompiled == True:\n",
        "  text1 = \"aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9TaGlyb21peWFHYW1lci9kZXBlbmRlbmNpYXMvcmVzb2x2ZS9tYWluL2RlcGVuZGVuY2llc19SVkNfUHJvamVjdF9pbmZlci56aXA=\"\n",
        "  text2 = \"ZGVwZW5kZW5jaWVzX1JWQ19Qcm9qZWN0X2luZmVyLnppcA==\"\n",
        "  text1 = base64.b64decode(text1).decode('utf-8')\n",
        "  text2 = base64.b64decode(text2).decode('utf-8')\n",
        "  Path(\"/content/drive/MyDrive/RVCDataset\").mkdir(parents=True, exist_ok=True)\n",
        "  Path(\"/content/drive/MyDrive/RVCDataset/Backup\").mkdir(parents=True, exist_ok=True)\n",
        "  !sudo apt install ffmpeg python3.10-venv aria2\n",
        "  !sudo apt-get install libsamplerate0-dev\n",
        "  arquivo_zip = '/content/dependencies_RVC_Project_infer.zip'\n",
        "  pasta_destino = '/content/dependencies'\n",
        "  Path('/content/arquivos').mkdir(parents=True, exist_ok=True)\n",
        "  !aria2c --console-log-level=error -x 16 -s 16 -k 1M {text1} -d /content -o {text2}\n",
        "  with zipfile.ZipFile(arquivo_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(pasta_destino)\n",
        "  !rm /content/dependencies_RVC_Project_infer.zip\n",
        "  sys.path.append(\"/content/dependencies\")\n",
        "  !wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | gpg --dearmor - | sudo tee /etc/apt/trusted.gpg.d/kitware.gpg >/dev/null\n",
        "  !sudo apt-add-repository \"deb https://apt.kitware.com/ubuntu/ $(lsb_release -cs) main\" -y\n",
        "  !sudo apt update\n",
        "  !sudo apt install kitware-archive-keyring\n",
        "  !sudo rm /etc/apt/trusted.gpg.d/kitware.gpg\n",
        "  !sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 6AF7F09730B3F0A4\n",
        "  !sudo apt update\n",
        "  !sudo apt-get install libsamplerate0-dev g++ make cmake\n",
        "  if voc_extra_files == True:\n",
        "    !git clone https://github.com/ZFTurbo/Music-Source-Separation-Training.git\n",
        "    !wget -P Music-Source-Separation-Training/models \"https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_317_sdr_12.9755.ckpt\"\n",
        "    !wget -P Music-Source-Separation-Training/models \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/model_bs_roformer_ep_317_sdr_12.9755.yaml\"\n",
        "    !rm Music-Source-Separation-Training/utils.py\n",
        "    !rm Music-Source-Separation-Training/requirements.txt\n",
        "    !rm Music-Source-Separation-Training/inference.py\n",
        "    !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/utils.py\"\n",
        "    !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/requirements.txt\"\n",
        "    !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/inference.py\"\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/spectograma.py\" # Spectograma\n",
        "  !wget -P ./arquivos \"https://github.com/ShiromiyaG/RVC-AI-Cover-Maker/releases/download/Dependencies/karokee_4band_v2_sn.pth\" # karokee\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/download_checks.json\" # download_checks\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/reverbpedalboard.py\" # reverb_pedalboard\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/mix.py\" # mix\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://github.com/shirounanashi/OrpheusDL.git\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://git.ovosimpatico.com/ovosimpatico/orpheusdl-deezer.git ./OrpheusDL/modules/deezer\n",
        "  !wget -P OrpheusDL/config \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Orpheus/settings.json\"\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion.git\n",
        "  %cd Retrieval-based-Voice-Conversion\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !rvc env create\n",
        "  from dotenv import load_dotenv, set_key\n",
        "  load_dotenv()\n",
        "  set_key(\".env\", \"rmvpe_root\", \"/content/Retrieval-based-Voice-Conversion\")\n",
        "  set_key(\".env\", \"hubert_path\", \"/content/Retrieval-based-Voice-Conversion/hubert_base.pt\")\n",
        "  %cd ../\n",
        "  !wget -P ./Retrieval-based-Voice-Conversion \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/RVC-Project/rvc.py\"\n",
        "  !wget -P ./Retrieval-based-Voice-Conversion \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/hubert_base.pt\"\n",
        "  !wget -P ./Retrieval-based-Voice-Conversion \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/rmvpe.pt\"\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "else:\n",
        "  !sudo apt install ffmpeg python3.10-venv\n",
        "  !pip install poetry pedalboard\n",
        "  !poetry config virtualenvs.create false\n",
        "  Path('/content/arquivos').mkdir(parents=True, exist_ok=True)\n",
        "  !sudo apt-get install libsamplerate0-dev\n",
        "  !git clone https://github.com/NextAudioGen/ultimatevocalremover_api.git\n",
        "  !pip install --no-deps pyrubberband dora-search retrying hydra-core>=1.1\n",
        "  !pip install yt-dlp[default] wget git+https://github.com/IAHispano/gdown\n",
        "  !rm ultimatevocalremover_api/requirements.txt\n",
        "  !rm ultimatevocalremover_api/src/models_dir/models.json\n",
        "  !rm ultimatevocalremover_api/src/models_dir/mdx/modelparams/model_data.json\n",
        "  !rm ultimatevocalremover_api/src/models_dir/vr_network/modelparams/model_data.json\n",
        "  !wget -P ultimatevocalremover_api/src/models_dir/ \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/UVRapi/models.json\"\n",
        "  !wget -P ultimatevocalremover_api/src/models_dir/mdx/modelparams/ \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/UVRapi/mdx/model_data.json\"\n",
        "  !wget -P ultimatevocalremover_api/src/models_dir/vr_network/modelparams/ \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/UVRapi/vr/model_data.json\"\n",
        "  !wget -P ultimatevocalremover_api/ \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/UVRapi/requirements.txt\"\n",
        "  %cd ultimatevocalremover_api\n",
        "  !pip install --upgrade --upgrade-strategy only-if-needed .\n",
        "  !wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | gpg --dearmor - | sudo tee /etc/apt/trusted.gpg.d/kitware.gpg >/dev/null\n",
        "  !sudo apt-add-repository \"deb https://apt.kitware.com/ubuntu/ $(lsb_release -cs) main\" -y\n",
        "  !sudo apt update\n",
        "  !sudo apt install kitware-archive-keyring\n",
        "  !sudo rm /etc/apt/trusted.gpg.d/kitware.gpg\n",
        "  !sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 6AF7F09730B3F0A4\n",
        "  !sudo apt update\n",
        "  !sudo apt-get install libsamplerate0-dev g++ make cmake\n",
        "  !pip install --upgrade --upgrade-strategy only-if-needed pydub soxr cmake audiofile samplerate==0.1.0\n",
        "  !python -m pip -q install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  %cd ../\n",
        "  if voc_extra_files == True:\n",
        "      !git clone https://github.com/ZFTurbo/Music-Source-Separation-Training.git\n",
        "      !wget -P Music-Source-Separation-Training/models \"https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_317_sdr_12.9755.ckpt\"\n",
        "      !wget -P Music-Source-Separation-Training/models \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/model_bs_roformer_ep_317_sdr_12.9755.yaml\"\n",
        "      !rm Music-Source-Separation-Training/utils.py\n",
        "      !rm Music-Source-Separation-Training/requirements.txt\n",
        "      !rm Music-Source-Separation-Training/inference.py\n",
        "      !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/utils.py\"\n",
        "      !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/requirements.txt\"\n",
        "      !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/inference.py\"\n",
        "      !pip install -r Music-Source-Separation-Training/requirements.txt\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/spectograma.py\" # Spectograma\n",
        "  !wget -P ./arquivos \"https://github.com/ShiromiyaG/RVC-AI-Cover-Maker/releases/download/Dependencies/karokee_4band_v2_sn.pth\" # karokee\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/download_checks.json\" # download_checks\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/reverbpedalboard.py\" # reverb_pedalboard\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/mix.py\" # mix\n",
        "  !pip install python-dotenv samplerate==0.1.0\n",
        "  from dotenv import load_dotenv, set_key\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://github.com/shirounanashi/OrpheusDL.git\n",
        "  %cd OrpheusDL\n",
        "  if not_clean_outputs != True:\n",
        "    !poetry install --no-root -q > /dev/null 2>&1\n",
        "    clear_output()\n",
        "  else:\n",
        "    !poetry install --no-root\n",
        "  %cd ../\n",
        "  !git clone https://git.ovosimpatico.com/ovosimpatico/orpheusdl-deezer.git ./OrpheusDL/modules/deezer\n",
        "  !wget -P OrpheusDL/config \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Orpheus/settings.json\"\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion.git\n",
        "  %cd Retrieval-based-Voice-Conversion\n",
        "  if not_clean_outputs != True:\n",
        "    !pip install rvc\n",
        "    clear_output()\n",
        "  else:\n",
        "    !poetry install --no-root\n",
        "  !rvc env create\n",
        "  load_dotenv()\n",
        "  set_key(\".env\", \"rmvpe_root\", \"/content/Retrieval-based-Voice-Conversion\")\n",
        "  set_key(\".env\", \"hubert_path\", \"/content/Retrieval-based-Voice-Conversion/hubert_base.pt\")\n",
        "  %cd ../\n",
        "  !wget -P ./Retrieval-based-Voice-Conversion \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/RVC-Project/rvc.py\"\n",
        "  !wget -P ./Retrieval-based-Voice-Conversion \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/hubert_base.pt\"\n",
        "  !wget -P ./Retrieval-based-Voice-Conversion \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/rmvpe.pt\"\n",
        "\n",
        "  #!pip --disable-pip-version-check install beautifulsoup4 ffmpeg ffmpeg-python==0.1.18 numpy==1.23.5 requests==2.31.0 tqdm faiss-cpu==1.7.3 librosa==0.9.1 pydub==0.25.1 pyworld==0.3.4 praat-parselmouth==0.4.2 resampy==0.4.2 scipy==1.11.1 sounddevice==0.4.6 soundfile==0.12.1 torchaudio==2.1.1 praat-parselmouth noisereduce fairseq numba onnxruntime onnxruntime_gpu==1.15.1 torch==2.1.1 torchcrepe==0.0.21 torchgen>=0.0.1 torch_directml torchvision==0.16.1 einops local-attention matplotlib==3.7.2 tensorboard ffmpy==0.3.1 tensorboardX edge-tts==6.1.9 pydantic fastapi uvicorn\n",
        "  !pip uninstall onnxruntime-gpu -y\n",
        "  !python -m pip -q install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Arquivo local\n",
        "from google.colab import files\n",
        "import os\n",
        "import fnmatch\n",
        "from pathlib import Path\n",
        "Path('/content/musicas/arquivos-originais').mkdir(parents=True, exist_ok=True)\n",
        "def search_files(pasta):\n",
        "    arquivos = []\n",
        "    for root, dirs, files in os.walk(pasta):\n",
        "        for file in files:\n",
        "            if file.endswith(\".mp3\") or file.endswith(\".flac\") or file.endswith(\".wav\"):\n",
        "                caminho_arquivo = os.path.join(root, file)\n",
        "                arquivos.append(caminho_arquivo)\n",
        "    return arquivos\n",
        "uploaded = files.upload()\n",
        "uploaded = search_files(\"/content\")\n",
        "for arquivo in uploaded:\n",
        "  !cp \"{arquivo}\" \"/content/musicas/arquivos-originais\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "33ZsDrrDxYld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Arquivo do Google Drive\n",
        "drive_path = \"/content/drive/MyDrive/RVC AI Cover Maker Input\" #@param {type:\"string\"}\n",
        "import os\n",
        "import fnmatch\n",
        "from pathlib import Path\n",
        "Path('/content/musicas/arquivos-originais').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def search_files(pasta):\n",
        "    arquivos = []\n",
        "    for root, dirs, files in os.walk(pasta):\n",
        "        for file in files:\n",
        "            if fnmatch.fnmatch(file, '*.mp3') or fnmatch.fnmatch(file, '*.flac') or fnmatch.fnmatch(file, '*.wav'):\n",
        "                arquivos.append(os.path.join(root, file))\n",
        "    return arquivos\n",
        "\n",
        "arquivos_encontrados = search_files(drive_path)\n",
        "\n",
        "for arquivo in arquivos_encontrados:\n",
        "    !cp \"{arquivo}\" \"/content/musicas/arquivos-originais\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "xifp_xRNyapb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFard4RtbcuZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if os.path.exists(\"/content/dependencies\"):\n",
        "  os.environ['PYTHONPATH'] = \"/content/dependencies\"\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display, clear_output\n",
        "from glob import glob\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "import json\n",
        "from yt_dlp import YoutubeDL\n",
        "import subprocess\n",
        "import uuid\n",
        "import gdown\n",
        "import zipfile\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from scipy.io import wavfile\n",
        "from rvc.modules.vc.modules import VC\n",
        "import uvr\n",
        "from uvr import models\n",
        "from uvr.utils.get_models import download_all_models\n",
        "import audiofile as af\n",
        "\n",
        "device = \"cuda\"\n",
        "# @title # Programa\n",
        "Path('/content/musicas').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/musicas/sem-intrumental').mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/drive/MyDrive/RVC AI Cover Maker\").mkdir(parents=True, exist_ok=True)\n",
        "input_folder = \"/content/musicas/arquivos-originais\"\n",
        "no_back_folder = \"/content/musicas/sem-back\"\n",
        "no_inst_folder = \"/content/musicas/sem-intrumental\"\n",
        "output_folder = \"/content/musicas/output-folder\"\n",
        "model_dir = \"/content/arquivos\"\n",
        "stage1_dir = \"/content/musicas/inst-etapa1\"\n",
        "stage2_dir = \"/content/musicas/inst-etapa2\"\n",
        "final_output_dir = \"/content/musicas/output_inst\"\n",
        "model_destination_folder = f\"/content/RVC_CLI/logs\"\n",
        "output_drive = \"/content/drive/MyDrive/RVC AI Cover Maker\"\n",
        "# @markdown ## Selecione uma das opções para fazer o donwload\n",
        "link_of_yt = \"\" #@param {type:\"string\"}\n",
        "link_of_deezer = \"\" #@param {type:\"string\"}\n",
        "# @markdown ##### Se você vai usar o Deezer\n",
        "bf_secret = \"\" #@param {type:\"string\"}\n",
        "track_url_key = \"\" #@param {type:\"string\"}\n",
        "arl = \"\" #@param {type:\"string\"}\n",
        "# @markdown ## Selecione os algoritmos de Ensemble (junção de espectograma dos áudios)\n",
        "# @markdown ##### Ensemble leva mais tempo, mas a qualidada final é maior\n",
        "Vocals_Ensemble = True #@param {type:\"boolean\"}\n",
        "algorithm_ensemble_vocals =  \"averege\" # @param ['averege', 'Max Spec', 'Min Spec'] {allow-input: false}\n",
        "Instrumental_Ensemble = True #@param {type:\"boolean\"}\n",
        "algorithm_ensemble_inst =  \"Max Spec\" # @param ['averege', 'Max Spec', 'Min Spec'] {allow-input: false}\n",
        "# @markdown ## Configurações do RVC\n",
        "rvc_model_link = \"\"  # @param {type:\"string\"}\n",
        "rvc_model_name = os.path.splitext(os.path.basename(rvc_model_link))\n",
        "f0method = \"rmvpe\"  # @param [\"pm\", \"harvest\", \"crepe\", \"rmvpe\"] {allow-input: false}\n",
        "Pitch = 0  # @param {type:\"slider\", min:-24, max:24, step:0}\n",
        "filter_radius = 3  # @param {type:\"slider\", min:0, max:10, step:0}\n",
        "rms_mix_rate = 0.8  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "protect = 0.5  # @param {type:\"slider\", min:0.0, max:0.5, step:0.1}\n",
        "index_rate = 0.7  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "# @markdown ## Reverb do áudio\n",
        "REVERB_SIZE = 0.15  # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "REVERB_WETNESS = 0.2 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "REVERB_DRYNESS = 0.8 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "REVERB_DAMPING = 0.7 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "# @markdown ## Opção de mixagem do áudio\n",
        "Voc_Vol = -4 # @param {type:\"slider\", min:-10, max:10, step:0}\n",
        "Inst_Vol = 0 # @param {type:\"slider\", min:-10, max:10, step:0}\n",
        "remove_noise_from_RVC = False  # @param{type:\"boolean\"}\n",
        "noise_db_limit = -30 # @param {type:\"slider\", min:-50, max:0, step:0.1}\n",
        "# @markdown ##### Para achar bugs, tem a opção de não limpar o output\n",
        "not_clean_outputs = False #@param {type:\"boolean\"}\n",
        "\n",
        "def verify_if_folder_is_empty(caminho_pasta):\n",
        "    if not os.listdir(caminho_pasta):\n",
        "        raise ValueError(\"Você não enviou um arquivo de áudio!\")\n",
        "\n",
        "def get_last_modified_file(directory, filter=''):\n",
        "  arquivos = glob(directory + \"/*\")\n",
        "  if filter != '':\n",
        "      arquivos = [arquivo for arquivo in arquivos if filter in arquivo]\n",
        "  if arquivos:\n",
        "      return max(arquivos, key=os.path.getmtime)\n",
        "  else:\n",
        "      return None\n",
        "\n",
        "def find_files(directory, extensions):\n",
        "  files = glob(f'{directory}/**/*{extensions}', recursive=True)\n",
        "  return files[0]\n",
        "\n",
        "def convert_to_mp3(input_file, output_file):\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "    audio.export(output_file, format=\"mp3\")\n",
        "\n",
        "if link_of_deezer != \"\":\n",
        "  with open('/content/OrpheusDL/config/settings.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "  data['modules']['deezer']['bf_secret'] = bf_secret\n",
        "  data['modules']['deezer']['track_url_key'] = track_url_key\n",
        "  data['modules']['deezer']['arl'] = arl\n",
        "\n",
        "  with open('/content/OrpheusDL/config/settings.json', 'w') as file:\n",
        "    json.dump(data, file, indent=4)\n",
        "\n",
        "if rvc_model_link == \"\":\n",
        "  raise ValueError(\"You didn't put a link to an RVC model\")\n",
        "\n",
        "if link_of_yt != \"\":\n",
        "  !yt-dlp --extract-audio -o \"/content/musicas/arquivos-originais/%(title)s.%(ext)s\"  --audio-format mp3 --audio-quality 0 \"{link_of_yt}\"\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  print(\"Seu áudio já foi baixado!\")\n",
        "\n",
        "if link_of_deezer != \"\":\n",
        "  if bf_secret != \"\" and track_url_key != \"\" and arl != \"\":\n",
        "    %cd OrpheusDL\n",
        "    !python orpheus.py \"{link_of_deezer}\"\n",
        "    if not_clean_outputs != True:\n",
        "      clear_output()\n",
        "    %cd ../\n",
        "    print(\"Seu áudio já foi baixado!\")\n",
        "  else:\n",
        "    raise ValueError(\"Você precisa fornecer a bf secret, track url key arl da sua conta Deezer Premium\")\n",
        "\n",
        "try:\n",
        "    verify_if_folder_is_empty(input_folder)\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "\n",
        "Path(input_folder).mkdir(parents=True, exist_ok=True)\n",
        "Path(no_back_folder).mkdir(parents=True, exist_ok=True)\n",
        "Path(no_inst_folder).mkdir(parents=True, exist_ok=True)\n",
        "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "Path(stage1_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(stage2_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(final_output_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(output_drive).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "input_files = glob(os.path.join(input_folder, '*.flac')) + glob(os.path.join(input_folder, '*.mp3')) + glob(os.path.join(input_folder, '*.wav'))\n",
        "\n",
        "for input_file in input_files:\n",
        "  print(\"Processando\", len(input_files), \"arquivos\")\n",
        "  if input_file.endswith(\".mp3\"):\n",
        "    flac_filename = os.path.splitext(input_file)[0] + '.flac'\n",
        "    if not os.path.exists(flac_filename):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "        audio.export(f\"{flac_filename}\", format=\"flac\")\n",
        "        os.remove(input_file)\n",
        "        input_file = flac_filename\n",
        "    MDX23C = models.MDXC(name=\"MDX23C-8KFFT-InstVoc_HQ\", other_metadata={'is_mdx_c_seg_def': False,'segment_size': 256,'batch_size': 8,'overlap_mdx23': 8,'semitone_shift': 0},device=device, logger=None)\n",
        "  res = MDX23C(input_file)\n",
        "  vocals = res[\"vocals\"]\n",
        "  af.write(f\"{no_inst_folder}/{basename}_MDX23C.wav\", vocals, MDX23C.sample_rate)\n",
        "  print(f\"O processo de {input_file} com MDX23C-8KFFT-InstVoc_HQ acabou!\")\n",
        "  if Vocals_Ensemble == True:\n",
        "    lista.append(get_last_modified_file(no_inst_folder))\n",
        "    !python Music-Source-Separation-Training/inference.py --model_type \"bs_roformer\" --config_path Music-Source-Separation-Training/models/model_bs_roformer_ep_317_sdr_12.9755.yaml --start_check_point Music-Source-Separation-Training/models/model_bs_roformer_ep_317_sdr_12.9755.ckpt --input_file \"{input_file}\" --store_dir \"{no_inst_folder}\"\n",
        "    print(f\"O processo de {input_file} com BSRoformer acabou!\")\n",
        "    lista.append(get_last_modified_file(no_inst_folder, \"Vocals\"))\n",
        "    ensemble_voc = os.path.join(no_inst_folder, f\"{basename}_ensemble1.flac\")\n",
        "    !python /content/arquivos/spectograma.py --audio_input \"{lista[0]}\" \"{lista[1]}\"--algorithm \"{algorithm_ensemble_vocals}\" --is_normalization False --wav_type_set \"PCM_16\" --save_path \"{ensemble_voc}\"\n",
        "  print(f\"O processo de Ensemble de {input_file} acabou!\")\n",
        "  input_file = get_last_modified_file(no_inst_folder)\n",
        "  no_inst_output = os.path.join(no_inst_folder, input_file)\n",
        "  Vr = models.VrNetwork(name=\"karokee_4band_v2_sn\", other_metadata={'normaliz': False, 'aggressiveness': 0.05,'window_size': 320,'batch_size': 8,'is_tta': True},device=device, logger=None)\n",
        "  res = Vr(no_inst_output)\n",
        "  vocals = res[\"vocals\"]\n",
        "  af.write(f\"{no_back_folder}/{basename}_karokee_4band_v2_sn.wav\", vocals, Vr.sample_rate)\n",
        "  torch.cuda.empty_cache()\n",
        "  filename = get_last_modified_file(no_back_folder)\n",
        "  no_back_output = os.path.join(no_back_folder, filename)\n",
        "  print(f\"O processamento de {filename} com o karokee_4band_v2_sn acabou!\")\n",
        "  MDX = models.MDX(name=\"Reverb_HQ\",  other_metadata={'segment_size': 256,'overlap': 0.75,'mdx_batch_size': 8,'semitone_shift': 0,'adjust': 1.08, 'denoise': False,'is_invert_spec': False,'is_match_frequency_pitch': True,'overlap_mdx': None},device=device, logger=None)\n",
        "  res = MDX(no_back_output)\n",
        "  no_reverb = res[\"no reverb\"]\n",
        "  af.write(f\"{output_folder}/{basename}_Reverb_HQ.wav\",  no_reverb, MDX.sample_rate)\n",
        "  torch.cuda.empty_cache()\n",
        "  print(f\"O processamento de {filename} com o UVR-DeEcho-DeReverb acabou!\")\n",
        "  print(\"Processamento doos vocais concluido.\")\n",
        "\n",
        "  ensemble1_inputs = []\n",
        "\n",
        "  # Pass 1\n",
        "  for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".flac\") and filename.endswith(\".mp3\") and filename.endswith(\".wav\"):\n",
        "        continue\n",
        "    if filename.endswith(\".mp3\"):\n",
        "      flac_filename = os.path.splitext(filename)[0] + '.flac'\n",
        "      if not os.path.exists(flac_filename):\n",
        "          audio = AudioSegment.from_mp3(filename)\n",
        "          audio.export(flac_filename, format=\"flac\")\n",
        "          os.remove(filename)\n",
        "          filename = flac_filename\n",
        "    file_path = os.path.join(input_folder, filename)\n",
        "    basename, _ = os.path.splitext(filename)\n",
        "    if Instrumental_Ensemble == True:\n",
        "      pass1_outputs = []\n",
        "      processed_models = []\n",
        "      model_names = [\"5_HP-Karaoke-UVR.pth\", \"UVR-MDX-NET-Inst_HQ_4.onnx\", \"htdemucs.yaml\"]\n",
        "      for model_name in model_names:\n",
        "          if model_name == \"5_HP-Karaoke-UVR.pth\":\n",
        "              Vr = models.VrNetwork(name=\"5_HP-Karaoke-UVR.pth\", other_metadata={'normaliz': False, 'aggressiveness': 0.05,'window_size': 320,'batch_size': 8,'is_tta': True},device=device, logger=None)\n",
        "              res = Vr(file_path)\n",
        "              instrumentals = res[\"instrumentals\"]\n",
        "              af.write(f\"{no_inst_folder}/{basename}_5_HP-Karaoke-UVR.pth.wav\", instrumentals, Vr.sample_rate)\n",
        "              torch.cuda.empty_cache()\n",
        "              processed_models.append(model_name)\n",
        "              print(f\"O processamento de {filename} com o {model_name} acabou!\")\n",
        "          if model_name == \"UVR-MDX-NET-Inst_HQ_4.onnx\":\n",
        "              MDX = models.MDX(name=\"UVR-MDX-NET-Inst_HQ_4.onnx\", other_metadata={'segment_size': 256,'overlap': 0.75,'mdx_batch_size': 8,'semitone_shift': 0,'adjust': 1.08, 'denoise': False,'is_invert_spec': False,'is_match_frequency_pitch': True,'overlap_mdx': None},device=device, logger=None)\n",
        "              res = MDX(file_path)\n",
        "              instrumentals = res[\"instrumentals\"]\n",
        "              af.write(f\"{stage1_dir}/{basename}_Inst-HQ4.wav\", instrumentals, MDX.sample_rate)\n",
        "              torch.cuda.empty_cache()\n",
        "              processed_models.append(model_name)\n",
        "              print(f\"{filename} processing with {model_name} is over!\")\n",
        "          if model_name == \"htdemucs.yaml\":\n",
        "              demucs = models.Demucs(name=\"htdemucs\",other_metadata={\"segment\":2, \"split\":True},device=device, logger=None)\n",
        "              res = demucs(file_path)\n",
        "              drum = res[\"drums\"]\n",
        "              bass = res[\"bass\"]\n",
        "              other = res[\"other\"]\n",
        "              af.write(f\"{stage1_dir}/{basename}_(Drums)_htdemucs.wav\", drum, demucs.sample_rate)\n",
        "              af.write(f\"{stage1_dir}/{basename}_(Bass)_htdemucs.wav\", bass, demucs.sample_rate)\n",
        "              af.write(f\"{stage1_dir}/{basename}_(Other)_htdemucs.wav\", other, demucs.sample_rate)\n",
        "              torch.cuda.empty_cache()\n",
        "              audio_files = [\n",
        "                  os.path.join(stage1_dir, f\"{basename}_(Drums)_htdemucs.wav\"),\n",
        "                  os.path.join(stage1_dir, f\"{basename}_(Bass)_htdemucs.wav\"),\n",
        "                  os.path.join(stage1_dir, f\"{basename}_(Other)_htdemucs.wav\")\n",
        "              ]\n",
        "\n",
        "              combined_audio = AudioSegment.from_file(audio_files[0], format=\"flac\")\n",
        "\n",
        "              for audio_file in audio_files[1:]:\n",
        "                  audio = AudioSegment.from_file(audio_file, format=\"flac\")\n",
        "                  combined_audio = combined_audio.overlay(audio)\n",
        "\n",
        "              combined_audio.export(f\"{stage1_dir}/{basename}_demucs_(Instrumental).flac\", format=\"flac\")\n",
        "\n",
        "              for audio_file in audio_files:\n",
        "                  os.remove(audio_file)\n",
        "              processed_models.append(model_name)\n",
        "              print(f\"O processo de {basename} com {model_name} acabou!\")\n",
        "          model_names = [model for model in model_names if model not in processed_models]\n",
        "\n",
        "    else:\n",
        "      model_name = \"UVR-MDX-NET-Inst_HQ_4.onnx\"\n",
        "      MDX = models.MDX(name=\"UVR-MDX-NET-Inst_HQ_4.onnx\", other_metadata={'segment_size': 256,'overlap': 0.75,'mdx_batch_size': 8,'semitone_shift': 0,'adjust': 1.08, 'denoise': False,'is_invert_spec': False,'is_match_frequency_pitch': True,'overlap_mdx': None},device=device, logger=None)\n",
        "      res = MDX(input_file)\n",
        "      instrumentals = res[\"instrumentals\"]\n",
        "      af.write(f\"{stage1_dir}/{basename}_Inst-HQ4.wav\", instrumentals, MDX.sample_rate)\n",
        "      torch.cuda.empty_cache()\n",
        "      final_output_path = os.path.join(stage1_dir, f\"{basename}_model_name_without_ext.flac\")\n",
        "      print(f\"O processo de {basename} com {model_name} acabou!\")\n",
        "\n",
        "  if Instrumental_Ensemble == True:\n",
        "    all_files = os.listdir(stage1_dir)\n",
        "    pass1_outputs_filtered = [os.path.join(stage1_dir, output) for output in all_files if \"Instrumental\" in output]\n",
        "    name = os.path.commonprefix(pass1_outputs_filtered)\n",
        "    # First Ensemble\n",
        "    ensemble1_output = os.path.join(stage1_dir, f\"{name}_ensemble1.flac\")\n",
        "    !python /content/arquivos/spectograma.py --audio_input \"{pass1_outputs_filtered[0]}\" \"{pass1_outputs_filtered[1]}\" \"{pass1_outputs_filtered[2]}\" --algorithm \"{algorithm_ensemble_inst}\" --is_normalization False --wav_type_set \"PCM_16\" --save_path \"{ensemble1_output}\"\n",
        "    print(\"O processo do primeiro Ensemble acabou!\")\n",
        "\n",
        "    # Pass 2\n",
        "    basename = os.path.splitext(os.path.basename(ensemble1_output))[0]\n",
        "    processed_models = []\n",
        "    pass2_outputs = []\n",
        "    model_names = [\"karokee_4band_v2_sn.pth\", \"UVR-MDX-NET-Inst_HQ_4.onnx\", \"Kim_Vocal_2.onnx\"]\n",
        "    for model_name in model_names:\n",
        "        if model_name == \"karokee_4band_v2_sn.pth\":\n",
        "          model_name_without_ext = model_name.split('.')[0]\n",
        "          output_path = os.path.join(stage2_dir, f\"{basename}_(Instrumental)_{model_name_without_ext}.flac\")\n",
        "          pass2_outputs.append(output_path)\n",
        "          Vr = models.VrNetwork(name=\"karokee_4band_v2_sn\", other_metadata={'aggressiveness': 0.05,'window_size': 320,'batch_size': 8,'is_tta': True},device=device, logger=None)\n",
        "          res = Vr(ensemble1_output)\n",
        "          instrumentals = res[\"instrumentals\"]\n",
        "          af.write(f\"{stage2_dir}/{basename}_karokee_4band_v2_sn.wav\", instrumentals, Vr.sample_rate)\n",
        "          torch.cuda.empty_cache()\n",
        "          processed_models.append(model_name)\n",
        "          print(f\"Processamento de {basename} com o {model_name} acabou!\")\n",
        "        else:\n",
        "          model_name_without_ext = model_name.split('.')[0]\n",
        "          output_path = os.path.join(stage2_dir, f\"{basename}_(Instrumental)_{model_name_without_ext}.flac\")\n",
        "          pass2_outputs.append(output_path)\n",
        "          MDX = models.MDX(name=f\"{model_name}\", other_metadata={'segment_size': 256,'overlap': 0.75,'mdx_batch_size': 8,'semitone_shift': 0,'adjust': 1.08, 'denoise': False,'is_invert_spec': False,'is_match_frequency_pitch': True,'overlap_mdx': None},device=device, logger=None)\n",
        "          res = MDX(input_file)\n",
        "          instrumentals = res[\"instrumentals\"]\n",
        "          af.write(f\"{stage2_dir}/{input_file}_{model_name}.wav\", instrumentals, MDX.sample_rate)\n",
        "          torch.cuda.empty_cache()\n",
        "          processed_models.append(model_name)\n",
        "          print(f\"Processamento de {basename} com o {model_name} acabou!\")\n",
        "        model_names = [model for model in model_names if model not in processed_models]\n",
        "\n",
        "    # Second Ensemble\n",
        "    all_files = os.listdir(stage2_dir)\n",
        "    pass2_outputs_filtered = [os.path.join(stage2_dir, output) for output in all_files if \"Instrumental\" in output]\n",
        "    final_output_path = os.path.join(final_output_dir, f\"{basename}_final_output.flac\")\n",
        "    !python /content/arquivos/spectograma.py --audio_input {pass2_outputs_filtered[0]} {pass2_outputs_filtered[1]} {pass2_outputs_filtered[2]} --algorithm {algorithm_ensemble_inst} --is_normalization False --wav_type_set \"PCM_16\" --save_path {final_output_path}\n",
        "    print(\"Processing of the second Ensemble is over!\")\n",
        "\n",
        "  if Instrumental_Ensemble == True:\n",
        "    final_song = [output for output in final_output_path if \"instrumental\" in output]\n",
        "  else:\n",
        "    final_song = [output for output in stage1_dir if \"instrumental\" in output]\n",
        "  print(\"Processamento dos instrumentais concluidos!\")\n",
        "  name = os.path.commonprefix(final_song)\n",
        "  # RVC part\n",
        "  print(\"Fazendo download do modelo...\")\n",
        "  filename = rvc_model_name\n",
        "  download_path = Path(model_destination_folder) / filename\n",
        "  if \"drive.google.com\" in rvc_model_link:\n",
        "      gdown.download(rvc_model_link, str(download_path), quiet=False)\n",
        "  else:\n",
        "      response = requests.get(rvc_model_link)\n",
        "      with open(download_path, 'wb') as file:\n",
        "          file.write(response.content)\n",
        "  if str(download_path).endswith(\".zip\"):\n",
        "    Path(f'/content/Retrieval-based-Voice-Conversion/{rvc_model_name}').mkdir(parents=True, exist_ok=True)\n",
        "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(f\"/content/Retrieval-based-Voice-Conversion/{rvc_model_name}\")\n",
        "  print(\"Download complete.\")\n",
        "  current_dir = \"/content/Retrieval-based-Voice-Conversion\"\n",
        "  model_folder = os.path.join(current_dir, f\"{rvc_model_name}\")\n",
        "\n",
        "  if not os.path.exists(model_folder):\n",
        "    raise FileNotFoundError(f\"Model directory not found: {model_folder}\")\n",
        "\n",
        "  files_in_folder = os.listdir(f\"{model_destination_folder}/{rvc_model_name}\")\n",
        "  pth_file = find_files(model_destination_folder, \".pth\")\n",
        "  index_file = find_files(model_destination_folder, \".index\")\n",
        "\n",
        "  if pth_file is None or index_file is None:\n",
        "    raise FileNotFoundError(\"No model found.\")\n",
        "\n",
        "  input_path = get_last_modified_file(final_output_path)\n",
        "  output_path = \"/content/output_rvc.flac\"\n",
        "  %cd Retrieval-based-Voice-Conversion\n",
        "  set_key(\".env\", \"index_root\", \"/content/Retrieval-based-Voice-Conversion/{rvc_model_name}\")\n",
        "  !python rvc.py --pth_file \"{pth_file}\" --index_rate \"{index_rate}\" --input_path \"{input_path}\" --pitch \"{pitch}\" --f0method \"{f0method}\" --filter_radius \"{filter_radius}\" --rms_mix_rate \"{rms_mix_rate}\" --protect \"{protect}\" --output_file \"{output_path}\"\n",
        "  %cd ../\n",
        "\n",
        "  # Reverb part\n",
        "  input_song = \"/content/output_rvc.wav\"\n",
        "  output_song = \"{final_song}\"\n",
        "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  !python /content/arquivos/reverbpedalboard.py -i \"{input_song}\" -rsize \"{REVERB_SIZE}\" -rwet \"{REVERB_WETNESS}\" -rdry \"{REVERB_DRYNESS}\" -rdamp \"{REVERB_DAMPING}\" -oformat \"WAV\"\n",
        "  output_path = f\"/content/output_rvc_mixed.wav\"\n",
        "  # Mix part\n",
        "  if remove_noise_from_RVC == True:\n",
        "    audio = AudioSegment.from_file(output_path)\n",
        "    db_limit = noise_db_limit\n",
        "    silenced_audio = AudioSegment.silent(duration=len(audio))\n",
        "    chunk_length = 100\n",
        "    for i in range(0, len(audio), chunk_length):\n",
        "        chunk = audio[i:i+chunk_length]\n",
        "        if chunk.dBFS > db_limit:\n",
        "            silenced_audio = silenced_audio.overlay(chunk, position=i)\n",
        "    silenced_audio.export(output_path, format=\"wav\")\n",
        "  output_mix = f\"/content/{name}_{rvc_model_name}.flac\"\n",
        "\n",
        "  !python /content/arquivos/mix.py --audio_paths  \"{output_path}\" \"{output_song}\" --output_path \"{output_mix}\" --main_gain \"{Voc_Vol}\" --inst_gain \"{Inst_Vol}\" --output_format \"FLAC\"\n",
        "\n",
        "  convert_to_mp3(output_mix, name)\n",
        "\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !cp \"{output_mix}\" \"{output_drive}\"\n",
        "  print(\"O arquivo FLAC está disponível na pasta \\\"RVC AI Cover Maker\\\" do seu Drive!\")\n",
        "  print(\"E o MP3 no player abaixo!\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}