{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **RVC AI Cover Maker**\n",
        "Created by [ShiromiyaG](https://github.com/ShiromiyaG)\n",
        "- Colab inspired on [AICoverGen](https://github.com/SociallyIneptWeeb/AICoverGen) by [SociallyIneptWeeb](https://github.com/SociallyIneptWeeb)\n",
        "- Uses the [blaise-tk](https://github.com/blaise-tk) version of [RVC_CLI](https://github.com/blaise-tk/RVC_CLI)"
      ],
      "metadata": {
        "id": "q2v07vI0d3tU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0mfD-nIXC_M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from IPython.display import clear_output\n",
        "import subprocess\n",
        "import fileinput\n",
        "import zipfile\n",
        "import shutil\n",
        "import sys\n",
        "import base64\n",
        "import tarfile\n",
        "\n",
        "def extract_tar_file(tar_file_path, destination_path):\n",
        "    if not Path(tar_file_path).exists():\n",
        "        print(f\"Tar file {tar_file_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    extraction_failed = False\n",
        "\n",
        "    with tarfile.open(tar_file_path, \"r:gz\") as tar:\n",
        "        for member in tar.getmembers():\n",
        "            try:\n",
        "                tar.extract(member, destination_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to extract file {member.name}: {e}\")\n",
        "                extraction_failed = True\n",
        "\n",
        "    print(f\"Extraction of {tar_file_path} to {destination_path} completed.\")\n",
        "\n",
        "    if os.path.exists(tar_file_path):\n",
        "        try:\n",
        "            os.remove(tar_file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to remove tar file {tar_file_path}: {e}\")\n",
        "\n",
        "    if extraction_failed:\n",
        "        print(\"Extraction encountered errors.\")\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "Path('/content/drive/MyDrive/RVC AI Cover Maker Input').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/musicas/arquivos-originais').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/dependencies').mkdir(parents=True, exist_ok=True)\n",
        "os.chdir(\"/content\")\n",
        "# @title # **Install**\n",
        "# @markdown ##### Yes, it takes time\n",
        "# @markdown ##### Leave the extra files enabled only if you are going to use ensemble on vocals\n",
        "voc_extra_files = True #@param {type:\"boolean\"}\n",
        "# @markdown ##### To find bugs, you have the option of not clearing the output **(Causes crashes)**\n",
        "not_clean_outputs = False #@param {type:\"boolean\"}\n",
        "# @markdown ##### Install precompiled pip dependencies for faster installation **(May be dated)**\n",
        "precompiled = True #@param {type:\"boolean\"}\n",
        "!sudo apt install ffmpeg python3.10-venv aria2 libsamplerate0-dev\n",
        "!pip install pydub\n",
        "if voc_extra_files == True:\n",
        "    !git clone https://github.com/ZFTurbo/Music-Source-Separation-Training.git\n",
        "    !aria2c --console-log-level=error -x 16 -s 16 -k 1M https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_317_sdr_12.9755.ckpt -d Music-Source-Separation-Training/models -o model_bs_roformer_ep_317_sdr_12.9755.ckpt\n",
        "    !aria2c --console-log-level=error -x 16 -s 16 -k 1M https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/model_bs_roformer_ep_317_sdr_12.9755.yaml -d Music-Source-Separation-Training/models -o model_bs_roformer_ep_317_sdr_12.9755.yaml\n",
        "    !aria2c --console-log-level=error -x 16 -s 16 -k 1M https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/MDX23C-8KFFT-InstVoc_HQ.ckpt -d Music-Source-Separation-Training/models -o MDX23C-8KFFT-InstVoc_HQ.ckpt\n",
        "    !aria2c --console-log-level=error -x 16 -s 16 -k 1M https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/mdx_c_configs/model_2_stem_full_band_8k.yaml -d Music-Source-Separation-Training/models -o model_2_stem_full_band_8k.yaml\n",
        "    !rm Music-Source-Separation-Training/utils.py\n",
        "    !rm Music-Source-Separation-Training/requirements.txt\n",
        "    !rm Music-Source-Separation-Training/inference.py\n",
        "    !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/utils.py\"\n",
        "    !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/requirements.txt\"\n",
        "    !wget -P Music-Source-Separation-Training \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Music-Source-Separation/inference.py\"\n",
        "    if precompiled == False:\n",
        "      !pip install requirements.txt\n",
        "if precompiled == True:\n",
        "  arquivo_zip = '/content/RVCAICoverMakerDeps.tar.gz'\n",
        "  pasta_destino = '/content/dependencies'\n",
        "  Path('/content/arquivos').mkdir(parents=True, exist_ok=True)\n",
        "  !aria2c --console-log-level=error -x 16 -s 16 -k 1M https://huggingface.co/ShiromiyaGamer/dependencias/resolve/main/RVCAICoverMakerDepsTeste.tar.gz -d /content -o RVCAICoverMakerDeps.tar.gz\n",
        "  source_path = \"/content/RVCAICoverMakerDeps.tar.gz\"\n",
        "  destination_path = \"/\"\n",
        "  extract_tar_file(source_path, destination_path)\n",
        "  !wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | gpg --dearmor - | sudo tee /etc/apt/trusted.gpg.d/kitware.gpg >/dev/null\n",
        "  !sudo apt-add-repository \"deb https://apt.kitware.com/ubuntu/ $(lsb_release -cs) main\" -y\n",
        "  !sudo apt update\n",
        "  !sudo apt install kitware-archive-keyring\n",
        "  !sudo rm /etc/apt/trusted.gpg.d/kitware.gpg\n",
        "  !sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 6AF7F09730B3F0A4\n",
        "  !sudo apt update\n",
        "  !sudo apt-get install libsamplerate0-dev g++ make cmake\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/spectograma.py\" # Spectograma\n",
        "  !aria2c --console-log-level=error -x 16 -s 16 -k 1M https://github.com/ShiromiyaG/RVC-AI-Cover-Maker/releases/download/Dependencies/karokee_4band_v2_sn.pth -d arquivos -o karokee_4band_v2_sn.pth\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/download_checks.json\" # download_checks\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/reverbpedalboard.py\" # reverb_pedalboard\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/mix.py\" # mix\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://github.com/shirounanashi/OrpheusDL.git\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://git.ovosimpatico.com/ovosimpatico/orpheusdl-deezer.git ./OrpheusDL/modules/deezer\n",
        "  !wget -P OrpheusDL/config \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Orpheus/settings.json\"\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://github.com/shirounanashi/RVC_CLI.git\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !wget -P ./RVC_CLI \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/fcpe.pt\"\n",
        "  !wget -P ./RVC_CLI \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/hubert_base.pt\"\n",
        "  !wget -P ./RVC_CLI \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/rmvpe.pt\"\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "else:\n",
        "  !pip install poetry pedalboard\n",
        "  !poetry config virtualenvs.create false\n",
        "  Path('/content/arquivos').mkdir(parents=True, exist_ok=True)\n",
        "  !sudo apt-get install libsamplerate0-dev\n",
        "  !git clone https://github.com/NextAudioGen/ultimatevocalremover_api.git\n",
        "  !pip install --no-deps pyrubberband dora-search retrying hydra-core>=1.1\n",
        "  !pip install yt-dlp[default] wget git+https://github.com/IAHispano/gdown\n",
        "  !rm ultimatevocalremover_api/requirements.txt\n",
        "  !rm ultimatevocalremover_api/src/models_dir/models.json\n",
        "  !rm ultimatevocalremover_api/src/models_dir/mdx/modelparams/model_data.json\n",
        "  !rm ultimatevocalremover_api/src/models_dir/vr_network/modelparams/model_data.json\n",
        "  !wget -P ultimatevocalremover_api/src/models_dir/ \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/UVRapi/models.json\"\n",
        "  !wget -P ultimatevocalremover_api/src/models_dir/mdx/modelparams/ \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/UVRapi/mdx/model_data.json\"\n",
        "  !wget -P ultimatevocalremover_api/src/models_dir/vr_network/modelparams/ \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/UVRapi/vr/model_data.json\"\n",
        "  !wget -P ultimatevocalremover_api/ \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/UVRapi/requirements.txt\"\n",
        "  %cd ultimatevocalremover_api\n",
        "  !pip install --upgrade --upgrade-strategy only-if-needed .\n",
        "  !wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | gpg --dearmor - | sudo tee /etc/apt/trusted.gpg.d/kitware.gpg >/dev/null\n",
        "  !sudo apt-add-repository \"deb https://apt.kitware.com/ubuntu/ $(lsb_release -cs) main\" -y\n",
        "  !sudo apt update\n",
        "  !sudo apt install kitware-archive-keyring\n",
        "  !sudo rm /etc/apt/trusted.gpg.d/kitware.gpg\n",
        "  !sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 6AF7F09730B3F0A4\n",
        "  !sudo apt update\n",
        "  !sudo apt-get install libsamplerate0-dev g++ make cmake\n",
        "  !pip install --upgrade --upgrade-strategy only-if-needed pydub soxr cmake audiofile samplerate==0.1.0\n",
        "  !python -m pip -q install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  %cd ../\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/spectograma.py\" # Spectograma\n",
        "  !wget -P ./arquivos \"https://github.com/ShiromiyaG/RVC-AI-Cover-Maker/releases/download/Dependencies/karokee_4band_v2_sn.pth\"\n",
        "  !aria2c --console-log-level=error -x 16 -s 16 -k 1M https://github.com/ShiromiyaG/RVC-AI-Cover-Maker/releases/download/Dependencies/karokee_4band_v2_sn.pth -d arquivos -o karokee_4band_v2_sn.pth\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/download_checks.json\" # download_checks\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/reverbpedalboard.py\" # reverb_pedalboard\n",
        "  !wget -P ./arquivos \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Utils/mix.py\" # mix\n",
        "  !pip install python-dotenv samplerate==0.1.0\n",
        "  from dotenv import load_dotenv, set_key\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://github.com/shirounanashi/OrpheusDL.git\n",
        "  %cd OrpheusDL\n",
        "  if not_clean_outputs != True:\n",
        "    !poetry install --no-root -q > /dev/null 2>&1\n",
        "    clear_output()\n",
        "  else:\n",
        "    !poetry install --no-root\n",
        "  %cd ../\n",
        "  !git clone https://git.ovosimpatico.com/ovosimpatico/orpheusdl-deezer.git ./OrpheusDL/modules/deezer\n",
        "  !wget -P OrpheusDL/config \"https://raw.githubusercontent.com/ShiromiyaG/RVC-AI-Cover-Maker/main/src/Orpheus/settings.json\"\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !git clone https://github.com/shirounanashi/RVC_CLI.git\n",
        "  %cd RVC_CLI\n",
        "  if not_clean_outputs != True:\n",
        "    !poetry install --no-root > /dev/null 2>&1\n",
        "    clear_output()\n",
        "  else:\n",
        "    !poetry install --no-root\n",
        "  %cd ../\n",
        "  !wget -P ./RVC_CLI \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/fcpe.pt\"\n",
        "  !wget -P ./RVC_CLI \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/hubert_base.pt\"\n",
        "  !wget -P ./RVC_CLI \"https://huggingface.co/IAHispano/Applio/resolve/main/Resources/rmvpe.pt\"\n",
        "  #!pip --disable-pip-version-check install beautifulsoup4 ffmpeg ffmpeg-python==0.1.18 numpy==1.23.5 requests==2.31.0 tqdm faiss-cpu==1.7.3 librosa==0.9.1 pydub==0.25.1 pyworld==0.3.4 praat-parselmouth==0.4.2 resampy==0.4.2 scipy==1.11.1 sounddevice==0.4.6 soundfile==0.12.1 torchaudio==2.1.1 praat-parselmouth noisereduce fairseq numba onnxruntime onnxruntime_gpu==1.15.1 torch==2.1.1 torchcrepe==0.0.21 torchgen>=0.0.1 torch_directml torchvision==0.16.1 einops local-attention matplotlib==3.7.2 tensorboard ffmpy==0.3.1 tensorboardX edge-tts==6.1.9 pydantic fastapi uvicorn\n",
        "  !pip uninstall onnxruntime-gpu -y\n",
        "  !python -m pip -q install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **Local file upload**\n",
        "from google.colab import files\n",
        "import os\n",
        "import fnmatch\n",
        "from pathlib import Path\n",
        "Path('/content/musicas/arquivos-originais').mkdir(parents=True, exist_ok=True)\n",
        "def search_files(pasta):\n",
        "    arquivos = []\n",
        "    for root, dirs, files in os.walk(pasta):\n",
        "        for file in files:\n",
        "            if file.endswith(\".mp3\") or file.endswith(\".flac\") or file.endswith(\".wav\"):\n",
        "                caminho_arquivo = os.path.join(root, file)\n",
        "                arquivos.append(caminho_arquivo)\n",
        "    return arquivos\n",
        "uploaded = files.upload()\n",
        "uploaded = search_files(\"/content\")\n",
        "for arquivo in uploaded:\n",
        "  !cp \"{arquivo}\" \"/content/musicas/arquivos-originais\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "33ZsDrrDxYld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **File from Google Drive**\n",
        "drive_path = \"/content/drive/MyDrive/RVC AI Cover Maker Input\" #@param {type:\"string\"}\n",
        "import os\n",
        "import fnmatch\n",
        "from pathlib import Path\n",
        "Path('/content/musicas/arquivos-originais').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def search_files(pasta):\n",
        "    arquivos = []\n",
        "    for root, dirs, files in os.walk(pasta):\n",
        "        for file in files:\n",
        "            if fnmatch.fnmatch(file, '*.mp3') or fnmatch.fnmatch(file, '*.flac') or fnmatch.fnmatch(file, '*.wav'):\n",
        "                arquivos.append(os.path.join(root, file))\n",
        "    return arquivos\n",
        "\n",
        "arquivos_encontrados = search_files(drive_path)\n",
        "\n",
        "for arquivo in arquivos_encontrados:\n",
        "    !cp \"{arquivo}\" \"/content/musicas/arquivos-originais\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "xifp_xRNyapb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFard4RtbcuZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display, clear_output\n",
        "from glob import glob\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "import json\n",
        "import subprocess\n",
        "import uuid\n",
        "import gdown\n",
        "import zipfile\n",
        "import requests\n",
        "import torch\n",
        "import audiofile as af\n",
        "import uvr\n",
        "from uvr import models\n",
        "from uvr.utils.get_models import download_all_models\n",
        "\n",
        "# @title # **Program**\n",
        "Path('/content/musicas').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/musicas/sem-intrumental').mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/drive/MyDrive/RVC AI Cover Maker\").mkdir(parents=True, exist_ok=True)\n",
        "input_folder = \"/content/musicas/arquivos-originais\"\n",
        "no_back_folder = \"/content/musicas/sem-back\"\n",
        "no_inst_folder = \"/content/musicas/sem-intrumental\"\n",
        "output_folder = \"/content/musicas/output-folder\"\n",
        "model_dir = \"/content/arquivos\"\n",
        "stage1_dir = \"/content/musicas/inst-etapa1\"\n",
        "stage2_dir = \"/content/musicas/inst-etapa2\"\n",
        "final_output_dir = \"/content/musicas/output_inst\"\n",
        "model_destination_folder = f\"/content/RVC_CLI/logs\"\n",
        "output_drive = \"/content/drive/MyDrive/RVC AI Cover Maker\"\n",
        "# @markdown ## Select one of the options to download a song\n",
        "link_of_yt = \"\" #@param {type:\"string\"}\n",
        "link_of_deezer = \"\" #@param {type:\"string\"}\n",
        "# @markdown ##### If you are going to use Deezer to download\n",
        "bf_secret = \"\" #@param {type:\"string\"}\n",
        "track_url_key = \"\" #@param {type:\"string\"}\n",
        "arl = \"\" #@param {type:\"string\"}\n",
        "# @markdown ## Choose Ensemble algorithms\n",
        "# @markdown ##### Ensemble takes longer, but the quality is higher\n",
        "Vocals_Ensemble = True #@param {type:\"boolean\"}\n",
        "algorithm_ensemble_vocals =  \"averege\" # @param ['averege', 'Max Spec', 'Min Spec'] {allow-input: false}\n",
        "Instrumental_Ensemble = True #@param {type:\"boolean\"}\n",
        "algorithm_ensemble_inst =  \"Max Spec\" # @param ['averege', 'Max Spec', 'Min Spec'] {allow-input: false}\n",
        "# @markdown ## RVC Settings\n",
        "rvc_model_link = \"\"  # @param {type:\"string\"}\n",
        "rvc_model_name = os.path.splitext(os.path.basename(rvc_model_link))\n",
        "f0method = \"rmvpe\"  # @param [\"pm\", \"dio\", \"crepe\", \"crepe-tiny\", \"harvest\", \"rmvpe\", \"fcpe\", \"hybrid[rmvpe+fcpe]\"] {allow-input: false}\n",
        "Pitch = 0  # @param {type:\"slider\", min:-24, max:24, step:0}\n",
        "filter_radius = 3  # @param {type:\"slider\", min:0, max:10, step:0}\n",
        "rms_mix_rate = 0.8  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "protect = 0.5  # @param {type:\"slider\", min:0.0, max:0.5, step:0.1}\n",
        "index_rate = 0.7  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "hop_length = 128  # @param {type:\"slider\", min:1, max:512, step:0}\n",
        "clean_strength = 0.7  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "split_audio = False  # @param{type:\"boolean\"}\n",
        "clean_audio = False  # @param{type:\"boolean\"}\n",
        "autotune = False  # @param{type:\"boolean\"}\n",
        "# @markdown ## Audio Reverb\n",
        "REVERB_SIZE = 0.15  # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "REVERB_WETNESS = 0.2 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "REVERB_DRYNESS = 0.8 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "REVERB_DAMPING = 0.7 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "# @markdown ## Audio Mixing Options\n",
        "Voc_Vol = -4 # @param {type:\"slider\", min:-10, max:10, step:0}\n",
        "Inst_Vol = 0 # @param {type:\"slider\", min:-10, max:10, step:0}\n",
        "remove_noise_from_RVC = False  # @param{type:\"boolean\"}\n",
        "noise_db_limit = -30 # @param {type:\"slider\", min:-50, max:0, step:0.1}\n",
        "# @markdown ##### To find bugs, you have the option of not clearing the output\n",
        "not_clean_outputs = False #@param {type:\"boolean\"}\n",
        "\n",
        "Path(input_folder).mkdir(parents=True, exist_ok=True)\n",
        "Path(no_back_folder).mkdir(parents=True, exist_ok=True)\n",
        "Path(no_inst_folder).mkdir(parents=True, exist_ok=True)\n",
        "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "Path(stage1_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(stage2_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(final_output_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(output_drive).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def verify_if_folder_is_empty(caminho_pasta):\n",
        "    if not os.listdir(caminho_pasta):\n",
        "        raise ValueError(\"You haven't sent an audio file!\")\n",
        "\n",
        "def get_last_modified_file(directory, filter=''):\n",
        "  arquivos = glob(directory + \"/*\")\n",
        "  if filter != '':\n",
        "      arquivos = [arquivo for arquivo in arquivos if filter in arquivo]\n",
        "  if arquivos:\n",
        "      return max(arquivos, key=os.path.getmtime)\n",
        "  else:\n",
        "      return None\n",
        "\n",
        "def find_files(directory, extensions):\n",
        "  files = glob(f'{directory}/**/*{extensions}', recursive=True)\n",
        "  return files[0]\n",
        "\n",
        "def convert_to_mp3(input_file, output_file):\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "    audio.export(output_file, format=\"mp3\")\n",
        "\n",
        "if link_of_deezer != \"\":\n",
        "  with open('/content/OrpheusDL/config/settings.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "  data['modules']['deezer']['bf_secret'] = bf_secret\n",
        "  data['modules']['deezer']['track_url_key'] = track_url_key\n",
        "  data['modules']['deezer']['arl'] = arl\n",
        "\n",
        "  with open('/content/OrpheusDL/config/settings.json', 'w') as file:\n",
        "    json.dump(data, file, indent=4)\n",
        "\n",
        "if rvc_model_link == \"\":\n",
        "  raise ValueError(\"You didn't put a link to an RVC model\")\n",
        "\n",
        "if link_of_yt != \"\":\n",
        "  !yt-dlp --extract-audio -o \"/content/musicas/arquivos-originais/%(title)s.%(ext)s\"  --audio-format mp3 --audio-quality 0 \"{link_of_yt}\"\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "\n",
        "if link_of_deezer != \"\":\n",
        "  if bf_secret != \"\" and track_url_key != \"\" and arl != \"\":\n",
        "    %cd OrpheusDL\n",
        "    !python orpheus.py \"{link_of_deezer}\"\n",
        "    if not_clean_outputs != True:\n",
        "      clear_output()\n",
        "    %cd ../\n",
        "  else:\n",
        "    raise ValueError(\"VocÃª precisa fornecer a bf secret, track url key arl da sua conta Deezer Premium\")\n",
        "\n",
        "try:\n",
        "    verify_if_folder_is_empty(input_folder)\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "\n",
        "input_files = glob(os.path.join(input_folder, '*.flac')) + glob(os.path.join(input_folder, '*.mp3')) + glob(os.path.join(input_folder, '*.wav'))\n",
        "for input_file in input_files:\n",
        "  basename = os.path.basename(input_file)\n",
        "  print(\"Processing\", len(input_file), \"files\")\n",
        "  if input_files.endswith(\".mp3\"):\n",
        "    flac_filename = os.path.splitext(input_file)[0] + '.flac'\n",
        "    if not os.path.exists(flac_filename):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "        audio.export(f\"{flac_filename}\", format=\"flac\")\n",
        "        os.remove(input_file)\n",
        "        input_file = flac_filename\n",
        "  !python Music-Source-Separation-Training/inference.py --model_type \"mdx23c\" --config_path Music-Source-Separation-Training/models/model_2_stem_full_band_8k.yaml --start_check_point Music-Source-Separation-Training/models/MDX23C-8KFFT-InstVoc_HQ.ckpt --input_file \"{input_file}\" --store_dir \"{no_inst_folder}\"\n",
        "  if Vocals_Ensemble == True:\n",
        "    lista = []\n",
        "    lista.append(get_last_modified_file(no_inst_folder, \"Vocals\"))\n",
        "    !python Music-Source-Separation-Training/inference.py --model_type \"bs_roformer\" --config_path Music-Source-Separation-Training/models/model_bs_roformer_ep_317_sdr_12.9755.yaml --start_check_point Music-Source-Separation-Training/models/model_bs_roformer_ep_317_sdr_12.9755.ckpt --input_file \"{input_file}\" --store_dir \"{no_inst_folder}\"\n",
        "    lista.append(get_last_modified_file(no_inst_folder, \"Vocals\"))\n",
        "    ensemble_voc = os.path.join(no_inst_folder, f\"{basename}_ensemble1.wav\")\n",
        "    !python /content/arquivos/spectograma.py --audio_input \"{lista[0]}\" \"{lista[1]}\" --algorithm {algorithm_ensemble_vocals} --is_normalization False --wav_type_set \"PCM_16\" --save_path {ensemble_voc}\n",
        "  filename = get_last_modified_file(no_inst_folder)\n",
        "  no_inst_output = os.path.join(no_inst_folder, filename)\n",
        "  print(f\"{filename} processing with MDX23C-8KFFT-InstVoc_HQ is over!\")\n",
        "  Vr = models.VrNetwork(name=\"karokee_4band_v2_sn\", other_metadata={'normaliz': False, 'aggressiveness': 0.05,'window_size': 320,'batch_size': 8,'is_tta': True},device=device, logger=None)\n",
        "  res = Vr(no_inst_output)\n",
        "  vocals = res[\"vocals\"]\n",
        "  af.write(f\"{no_back_folder}/{basename}_karokee_4band_v2_sn.wav\", vocals, Vr.sample_rate)\n",
        "  torch.cuda.empty_cache()\n",
        "  filename = get_last_modified_file(no_back_folder)\n",
        "  no_back_output = os.path.join(no_back_folder, filename)\n",
        "  print(f\"{filename} processing with karokee_4band_v2_sn is over!\")\n",
        "  MDX = models.MDX(name=\"Reverb_HQ\",  other_metadata={'segment_size': 384,'overlap': 0.75,'mdx_batch_size': 8,'semitone_shift': 0,'adjust': 1.08, 'denoise': False,'is_invert_spec': False,'is_match_frequency_pitch': True,'overlap_mdx': None},device=device, logger=None)\n",
        "  res = MDX(no_back_output)\n",
        "  no_reverb = res[\"no reverb\"]\n",
        "  af.write(f\"{output_folder}/{basename}_Reverb_HQ.wav\",  no_reverb, MDX.sample_rate)\n",
        "  torch.cuda.empty_cache()\n",
        "  print(f\"{filename} processing with UVR-DeEcho-DeReverb is over!\")\n",
        "  print(\"Vocal processing completed.\")\n",
        "\n",
        "  ensemble1_inputs = []\n",
        "\n",
        "  # Pass 1\n",
        "  for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".flac\") and filename.endswith(\".mp3\") and filename.endswith(\".wav\"):\n",
        "        continue\n",
        "    if filename.endswith(\".mp3\"):\n",
        "      flac_filename = os.path.splitext(filename)[0] + '.flac'\n",
        "      if not os.path.exists(flac_filename):\n",
        "          audio = AudioSegment.from_mp3(filename)\n",
        "          audio.export(flac_filename, format=\"flac\")\n",
        "          os.remove(filename)\n",
        "          filename = flac_filename\n",
        "    file_path = os.path.join(input_folder, filename)\n",
        "    basename, _ = os.path.splitext(filename)\n",
        "    if Instrumental_Ensemble == True:\n",
        "      pass1_outputs = []\n",
        "      processed_models = []\n",
        "      model_names = [\"5_HP-Karaoke-UVR.pth\", \"UVR-MDX-NET-Inst_HQ_4.onnx\", \"htdemucs.yaml\"]\n",
        "      for model_name in model_names:\n",
        "          if model_name == \"5_HP-Karaoke-UVR.pth\":\n",
        "              Vr = models.VrNetwork(name=\"5_HP-Karaoke-UVR.pth\", other_metadata={'normaliz': False, 'aggressiveness': 0.05,'window_size': 320,'batch_size': 8,'is_tta': True},device=device, logger=None)\n",
        "              res = Vr(file_path)\n",
        "              instrumentals = res[\"instrumentals\"]\n",
        "              af.write(f\"{no_inst_folder}/{basename}_5_HP-Karaoke-UVR.pth.wav\", instrumentals, Vr.sample_rate)\n",
        "              torch.cuda.empty_cache()\n",
        "              processed_models.append(model_name)\n",
        "              print(f\"{filename} processing with {model_name} is over!\")\n",
        "          if model_name == \"UVR-MDX-NET-Inst_HQ_4.onnx\":\n",
        "              MDX = models.MDX(name=\"UVR-MDX-NET-Inst_HQ_4.onnx\", other_metadata={'segment_size': 256,'overlap': 0.75,'mdx_batch_size': 8,'semitone_shift': 0,'adjust': 1.08, 'denoise': False,'is_invert_spec': False,'is_match_frequency_pitch': True,'overlap_mdx': None},device=device, logger=None)\n",
        "              res = MDX(file_path)\n",
        "              instrumentals = res[\"instrumentals\"]\n",
        "              af.write(f\"{stage1_dir}/{basename}_Inst-HQ4.wav\", instrumentals, MDX.sample_rate)\n",
        "              torch.cuda.empty_cache()\n",
        "              processed_models.append(model_name)\n",
        "              print(f\"{filename} processing with {model_name} is over!\")\n",
        "          if model_name == \"htdemucs.yaml\":\n",
        "              demucs = models.Demucs(name=\"htdemucs\",other_metadata={\"segment\":2, \"split\":True},device=device, logger=None)\n",
        "              res = demucs(file_path)\n",
        "              drum = res[\"drums\"]\n",
        "              bass = res[\"bass\"]\n",
        "              other = res[\"other\"]\n",
        "              af.write(f\"{stage1_dir}/{basename}_(Drums)_htdemucs.wav\", drum, demucs.sample_rate)\n",
        "              af.write(f\"{stage1_dir}/{basename}_(Bass)_htdemucs.wav\", bass, demucs.sample_rate)\n",
        "              af.write(f\"{stage1_dir}/{basename}_(Other)_htdemucs.wav\", other, demucs.sample_rate)\n",
        "              torch.cuda.empty_cache()\n",
        "              audio_files = [\n",
        "                  os.path.join(stage1_dir, f\"{basename}_(Drums)_htdemucs.wav\"),\n",
        "                  os.path.join(stage1_dir, f\"{basename}_(Bass)_htdemucs.wav\"),\n",
        "                  os.path.join(stage1_dir, f\"{basename}_(Other)_htdemucs.wav\")\n",
        "              ]\n",
        "\n",
        "              combined_audio = AudioSegment.from_file(audio_files[0], format=\"flac\")\n",
        "\n",
        "              for audio_file in audio_files[1:]:\n",
        "                  audio = AudioSegment.from_file(audio_file, format=\"flac\")\n",
        "                  combined_audio = combined_audio.overlay(audio)\n",
        "\n",
        "              combined_audio.export(f\"{stage1_dir}/{basename}_demucs_(Instrumental).flac\", format=\"flac\")\n",
        "\n",
        "              for audio_file in audio_files:\n",
        "                  os.remove(audio_file)\n",
        "              processed_models.append(model_name)\n",
        "              print(f\"{filename} processing with {model_name} is over!\")\n",
        "          model_names = [model for model in model_names if model not in processed_models]\n",
        "\n",
        "    else:\n",
        "      model_name = \"UVR-MDX-NET-Inst_HQ_4.onnx\"\n",
        "      MDX = models.MDX(name=\"UVR-MDX-NET-Inst_HQ_4.onnx\", other_metadata={'segment_size': 256,'overlap': 0.75,'mdx_batch_size': 8,'semitone_shift': 0,'adjust': 1.08, 'denoise': False,'is_invert_spec': False,'is_match_frequency_pitch': True,'overlap_mdx': None},device=device, logger=None)\n",
        "      res = MDX(input_file)\n",
        "      instrumentals = res[\"instrumentals\"]\n",
        "      af.write(f\"{stage1_dir}/{basename}_Inst-HQ4.wav\", instrumentals, MDX.sample_rate)\n",
        "      torch.cuda.empty_cache()\n",
        "      processed_models.append(model_name)\n",
        "      final_output_path = os.path.join(stage1_dir, f\"{basename}_model_name_without_ext.flac\")\n",
        "      print(f\"{basename} processing with {model_name} is over!\")\n",
        "\n",
        "  if Instrumental_Ensemble == True:\n",
        "    all_files = os.listdir(stage1_dir)\n",
        "    pass1_outputs_filtered = [os.path.join(stage1_dir, output) for output in all_files if \"Instrumental\" in output]\n",
        "    name = os.path.commonprefix(pass1_outputs_filtered)\n",
        "    # First Ensemble\n",
        "    ensemble1_output = os.path.join(stage1_dir, f\"{name}_ensemble1.wav\")\n",
        "    !python /content/arquivos/spectograma.py --audio_input \"{pass1_outputs_filtered[0]}\" \"{pass1_outputs_filtered[1]}\" \"{pass1_outputs_filtered[2]}\" --algorithm \"{algorithm_ensemble_inst}\" --is_normalization False --wav_type_set \"PCM_16\" --save_path \"{ensemble1_output}\"\n",
        "    print(\"Processing of the first Ensemble is over!\")\n",
        "\n",
        "    # Pass 2\n",
        "    basename = os.path.splitext(os.path.basename(ensemble1_output))[0]\n",
        "    processed_models = []\n",
        "    pass2_outputs = []\n",
        "    model_names = [\"karokee_4band_v2_sn.pth\", \"UVR-MDX-NET-Inst_HQ_4.onnx\", \"Kim_Vocal_2.onnx\"]\n",
        "    for model_name in model_names:\n",
        "        if model_name == \"karokee_4band_v2_sn.pth\":\n",
        "          model_name_without_ext = model_name.split('.')[0]\n",
        "          output_path = os.path.join(stage2_dir, f\"{basename}_(Instrumental)_{model_name_without_ext}.flac\")\n",
        "          pass2_outputs.append(output_path)\n",
        "          Vr = models.VrNetwork(name=\"karokee_4band_v2_sn\", other_metadata={'aggressiveness': 0.05,'window_size': 320,'batch_size': 8,'is_tta': True},device=device, logger=None)\n",
        "          res = Vr(ensemble1_output)\n",
        "          instrumentals = res[\"instrumentals\"]\n",
        "          af.write(f\"{stage2_dir}/{basename}_karokee_4band_v2_sn.wav\", instrumentals, Vr.sample_rate)\n",
        "          torch.cuda.empty_cache()\n",
        "          processed_models.append(model_name)\n",
        "          print(f\"Processamento de {basename} com o {model_name} acabou!\")\n",
        "        else:\n",
        "          model_name_without_ext = model_name.split('.')[0]\n",
        "          output_path = os.path.join(stage2_dir, f\"{basename}_(Instrumental)_{model_name_without_ext}.flac\")\n",
        "          pass2_outputs.append(output_path)\n",
        "          MDX = models.MDX(name=f\"{model_name}\", other_metadata={'segment_size': 256,'overlap': 0.75,'mdx_batch_size': 8,'semitone_shift': 0,'adjust': 1.08, 'denoise': False,'is_invert_spec': False,'is_match_frequency_pitch': True,'overlap_mdx': None},device=device, logger=None)\n",
        "          res = MDX(input_file)\n",
        "          instrumentals = res[\"instrumentals\"]\n",
        "          af.write(f\"{stage2_dir}/{input_file}_{model_name}.wav\", instrumentals, MDX.sample_rate)\n",
        "          torch.cuda.empty_cache()\n",
        "          processed_models.append(model_name)\n",
        "          print(f\"Processamento de {basename} com o {model_name} acabou!\")\n",
        "        model_names = [model for model in model_names if model not in processed_models]\n",
        "\n",
        "    # Second Ensemble\n",
        "    all_files = os.listdir(stage2_dir)\n",
        "    pass2_outputs_filtered = [os.path.join(stage2_dir, output) for output in all_files if \"Instrumental\" in output]\n",
        "    final_output_path = os.path.join(final_output_dir, f\"{basename}_final_output.wav\")\n",
        "    !python /content/arquivos/spectograma.py --audio_input \"{pass2_outputs_filtered[0]}\" \"{pass2_outputs_filtered[1]}\" \"{pass2_outputs_filtered[2]}\" --algorithm \"{algorithm_ensemble_inst}\" --is_normalization False --wav_type_set \"PCM_16\" --save_path \"{final_output_path}\"\"\n",
        "    print(\"Processing of the second Ensemble is over!\")\n",
        "\n",
        "  if Instrumental_Ensemble == True:\n",
        "    final_song = [output for output in final_output_path if \"instrumental\" in output]\n",
        "  else:\n",
        "    final_song = [output for output in stage1_dir if \"instrumental\" in output]\n",
        "  print(\"Instrument processing complete!\")\n",
        "  name = os.path.commonprefix(final_song)\n",
        "  # RVC part\n",
        "  print(\"Downloading model...\")\n",
        "  filename = rvc_model_name\n",
        "  download_path = Path(model_destination_folder) / filename\n",
        "  if \"drive.google.com\" in rvc_model_link:\n",
        "      gdown.download(rvc_model_link, str(download_path), quiet=False)\n",
        "  else:\n",
        "      response = requests.get(rvc_model_link)\n",
        "      with open(download_path, 'wb') as file:\n",
        "          file.write(response.content)\n",
        "  if str(download_path).endswith(\".zip\"):\n",
        "    Path(f'/content/RVC_CLI/logs/{rvc_model_name}').mkdir(parents=True, exist_ok=True)\n",
        "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(f\"/content/RVC_CLI/logs/{rvc_model_name}\")\n",
        "  print(\"Download complete.\")\n",
        "  current_dir = \"/content/RVC_CLI\"\n",
        "  model_folder = os.path.join(current_dir, f\"logs/{rvc_model_name}\")\n",
        "\n",
        "  if not os.path.exists(model_folder):\n",
        "    raise FileNotFoundError(f\"Model directory not found: {model_folder}\")\n",
        "\n",
        "  files_in_folder = os.listdir(f\"{model_destination_folder}/{rvc_model_name}\")\n",
        "  pth_file = find_files(model_destination_folder, \".pth\")\n",
        "  index_file = find_files(model_destination_folder, \".index\")\n",
        "\n",
        "  if pth_file is None or index_file is None:\n",
        "    raise FileNotFoundError(\"No model found.\")\n",
        "\n",
        "  input_path = get_last_modified_file(final_output_path)\n",
        "  output_path = \"/content/output_rvc.flac\"\n",
        "  export_format = \"FLAC\"\n",
        "  %cd RVC_CLI\n",
        "  !python main.py infer --f0up_key \"{Pitch}\" --filter_radius \"{filter_radius}\" --index_rate \"{index_rate}\" --hop_length \"{hop_length}\" --rms_mix_rate \"{rms_mix_rate}\" --protect \"{protect}\" --f0autotune \"{autotune}\" --f0method \"{f0method}\" --input_path \"{input_path}\" --output_path \"{output_path}\" --pth_path \"{pth_file}\" --index_path \"{index_file}\" --split_audio \"{split_audio}\" --clean_audio \"{clean_audio}\" --clean_strength \"{clean_strength}\" --export_format \"FLAC\"\n",
        "  %cd ../\n",
        "  output_path = output_path.replace(\".flac\", f\".{export_format.lower()}\")\n",
        "\n",
        "  # Reverb part\n",
        "  input_song = \"/content/output_rvc.flac\"\n",
        "  output_song = \"{final_song}\"\n",
        "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  !python /content/arquivos/reverbpedalboard.py -i \"{input_song}\" -rsize \"{REVERB_SIZE}\" -rwet \"{REVERB_WETNESS}\" -rdry \"{REVERB_DRYNESS}\" -rdamp \"{REVERB_DAMPING}\" -oformat \"WAV\"\n",
        "  output_path = f\"/content/output_rvc_mixed.wav\"\n",
        "  # Mix part\n",
        "  if remove_noise_from_RVC == True:\n",
        "    audio = AudioSegment.from_file(output_path)\n",
        "    db_limit = noise_db_limit\n",
        "    silenced_audio = AudioSegment.silent(duration=len(audio))\n",
        "    chunk_length = 100\n",
        "    for i in range(0, len(audio), chunk_length):\n",
        "        chunk = audio[i:i+chunk_length]\n",
        "        if chunk.dBFS > db_limit:\n",
        "            silenced_audio = silenced_audio.overlay(chunk, position=i)\n",
        "    silenced_audio.export(output_path, format=\"wav\")\n",
        "\n",
        "  output_mix = f\"/content/{name}_{rvc_model_name}.flac\"\n",
        "\n",
        "  !python /content/arquivos/mix.py --audio_paths  \"{output_path}\" \"{output_song}\" --output_path \"{output_mix}\" --main_gain \"{Voc_Vol}\" --inst_gain \"{Inst_Vol}\" --output_format \"FLAC\"\n",
        "\n",
        "  if not_clean_outputs != True:\n",
        "    clear_output()\n",
        "  !cp \"{output_mix}\" \"{output_drive}\"\n",
        "  print(\"The FLAC file is available in \\\"RVC AI Cover Maker\\\" folder on your Drive!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}